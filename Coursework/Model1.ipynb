{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1\n",
    "\n",
    "This includes the modelling for the first dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arm length (m)</th>\n",
       "      <th>Ball weight (kg)</th>\n",
       "      <th>Ball radius (mm)</th>\n",
       "      <th>Air temperature (deg C)</th>\n",
       "      <th>Spring constant (N per m)</th>\n",
       "      <th>Device weight (kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.080169</td>\n",
       "      <td>0.295992</td>\n",
       "      <td>-1.672519</td>\n",
       "      <td>-0.168624</td>\n",
       "      <td>1.894558</td>\n",
       "      <td>0.153154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.530990</td>\n",
       "      <td>2.110671</td>\n",
       "      <td>2.590811</td>\n",
       "      <td>1.489631</td>\n",
       "      <td>0.522109</td>\n",
       "      <td>0.717173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.870428</td>\n",
       "      <td>1.411470</td>\n",
       "      <td>0.095824</td>\n",
       "      <td>-1.619596</td>\n",
       "      <td>1.728095</td>\n",
       "      <td>0.336045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.847603</td>\n",
       "      <td>1.505591</td>\n",
       "      <td>-0.684953</td>\n",
       "      <td>0.245940</td>\n",
       "      <td>-1.370214</td>\n",
       "      <td>0.139830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.379235</td>\n",
       "      <td>0.814349</td>\n",
       "      <td>-0.073455</td>\n",
       "      <td>-1.619596</td>\n",
       "      <td>-1.303393</td>\n",
       "      <td>-0.271138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Arm length (m)  Ball weight (kg)  Ball radius (mm)  \\\n",
       "0       -0.080169          0.295992         -1.672519   \n",
       "1       -0.530990          2.110671          2.590811   \n",
       "2        1.870428          1.411470          0.095824   \n",
       "3       -0.847603          1.505591         -0.684953   \n",
       "4       -1.379235          0.814349         -0.073455   \n",
       "\n",
       "   Air temperature (deg C)  Spring constant (N per m)  Device weight (kg)  \n",
       "0                -0.168624                   1.894558            0.153154  \n",
       "1                 1.489631                   0.522109            0.717173  \n",
       "2                -1.619596                   1.728095            0.336045  \n",
       "3                 0.245940                  -1.370214            0.139830  \n",
       "4                -1.619596                  -1.303393           -0.271138  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('../Data/dataset1_scaled.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arm length (m)\n",
       "0.291903    0.0\n",
       "0.247545    1.0\n",
       "0.483827    1.0\n",
       "0.216393    0.0\n",
       "0.164084    0.0\n",
       "Name: Target hit, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('../Data/dataset1.csv', index_col = 0)\n",
    "y = y[y.columns[-1]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras stuff\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y_binary = to_categorical(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_binary, test_size = 0.8, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    Dense(input_shape = (6,), units = 10, activation = 'relu')\n",
    ") # add first dense layer\n",
    "model.add(\n",
    "    Dense(units = 10, activation = 'sigmoid')\n",
    ")\n",
    "model.add(\n",
    "    Dense(units = 2, activation = 'sigmoid')\n",
    ")\n",
    "\n",
    "#model.add(\n",
    "#    BatchNormalization()\n",
    "#)\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'sgd',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 990us/step - loss: 0.6880 - accuracy: 0.5075\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5075\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5075\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.5100\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5150\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.5150\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5225\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.5275\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.5350\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6783 - accuracy: 0.5400\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.5400\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.5500\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.5575\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.5625\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.5650\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.5800\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.5850\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.6025\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6710 - accuracy: 0.6050\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6703 - accuracy: 0.6100\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6695 - accuracy: 0.6150\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.6225\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.6275\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.6425\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6400\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.6475\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.6500\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.6525\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.6450\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.6500\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.6450\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6450\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6400\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6375\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6400\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.6400\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6450\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6425\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6425\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6400\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6425\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6400\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.6450\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6575\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6600\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6600\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6675\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.6775\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6850\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6975\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.7075\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.7075\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.7125\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.7125\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.7125\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.7200\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6389 - accuracy: 0.7175\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.7200\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.7225\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.7250\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.7275\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7325\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.7300\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.7325\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.7350\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.7350\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.7375\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.7425\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6242 - accuracy: 0.7425\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.7425\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.7450\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6185 - accuracy: 0.7525\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6170 - accuracy: 0.7525\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6155 - accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6139 - accuracy: 0.7525\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6123 - accuracy: 0.7550\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.7575\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6091 - accuracy: 0.7625\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.7650\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.7675\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6039 - accuracy: 0.7750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.7725\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6003 - accuracy: 0.7750\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.7725\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7775\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.7775\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.7775\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.7800\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.7800\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.7800\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.7825\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7825\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.7850\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.7850\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.7850\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7925\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7925\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7925\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a1c5bf1d0>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5584505796432495 / Test accuracy: 0.8118749856948853\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 10)                70        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 202\n",
      "Trainable params: 202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade numpy==1.18\n",
    "#!pip install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc4\n",
    "#!pip install autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import autokeras as ak\\n\\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.8, random_state = 23)\\n\\nclf = ak.StructuredDataClassifier(\\n    overwrite=True,\\n    max_trials=10)\\n\\nclf.fit(X_train, y_train,\\n    epochs=10)\\n\\n# Predict with the best model.\\n\\npredicted_y = clf.predict(X_test)\\n# Evaluate the best model with testing data.\\nclf.evaluate(X_test, y_test)'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import autokeras as ak\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.8, random_state = 23)\n",
    "\n",
    "clf = ak.StructuredDataClassifier(\n",
    "    overwrite=True,\n",
    "    max_trials=10)\n",
    "\n",
    "clf.fit(X_train, y_train,\n",
    "    epochs=10)\n",
    "\n",
    "# Predict with the best model.\n",
    "\n",
    "predicted_y = clf.predict(X_test)\n",
    "# Evaluate the best model with testing data.\n",
    "clf.evaluate(X_test, y_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import tensorflow as tf\\n\\ntrain_set = tf.data.Dataset.from_tensor_slices((X_train.astype(np.unicode), y_train))\\ntest_set = tf.data.Dataset.from_tensor_slices((X_test.to_numpy().astype(np.unicode), y_test))\\n\\nclf = ak.StructuredDataClassifier(\\n    overwrite=True,\\n    max_trials=3)\\n# Feed the tensorflow Dataset to the classifier.\\nclf.fit(train_set, epochs=10)\\n# Predict with the best model.\\npredicted_y = clf.predict(test_set)\\n# Evaluate the best model with testing data.\\nprint(clf.evaluate(test_set))'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import tensorflow as tf\n",
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices((X_train.astype(np.unicode), y_train))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test.to_numpy().astype(np.unicode), y_test))\n",
    "\n",
    "clf = ak.StructuredDataClassifier(\n",
    "    overwrite=True,\n",
    "    max_trials=3)\n",
    "# Feed the tensorflow Dataset to the classifier.\n",
    "clf.fit(train_set, epochs=10)\n",
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(test_set)\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(test_set))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = clf.export_model()\\nmodel.summary()'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model = clf.export_model()\n",
    "model.summary()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target: to beat a model with accuracy = [0.36, 0.8925] (based on autokeras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step - loss: 1.0784 - accuracy: 0.9087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0784125328063965, 0.9087499976158142]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(input_shape = (6,), units = 32),\n",
    "        Dense(units = 32, activation = 'relu'),\n",
    "        Dense(units = 2, activation = 'tanh')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'sgd',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "y_binary = to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_binary, test_size = 0.8, random_state = 23)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 100, verbose = 0)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score\n",
    "\n",
    "# model is terrible..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.4663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49785998463630676, 0.4662500023841858]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(input_shape = (6,), units = 32),\n",
    "        Dense(units = 32, activation = 'relu'),\n",
    "        Dense(units = 32),\n",
    "        Dense(units = 32, activation = 'relu'),\n",
    "        Dense(units = 2, activation = 'tanh')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'sgd',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "y_binary = to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_binary, test_size = 0.8, random_state = 23)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 100, verbose = 0)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding code to make this process smoother..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LayerNormalization \n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "def uncompiled_model():\n",
    "    inputs =  Input(shape = (6,), name = 'Data')\n",
    "    x = Dense(4, activation = 'relu', name = 'dense_1')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(4, activation = 'relu', name = 'dense_2')(x)\n",
    "\n",
    "    outputs = Dense(2, activation = 'softmax', name = 'TargetHit')(x)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def compile_model():\n",
    "    model = uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"sgd\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\",\n",
    "                 \"binary_accuracy\",\n",
    "                 \"binary_crossentropy\",\n",
    "                 \"categorical_accuracy\"\n",
    "                ],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.8925 - binary_accuracy: 0.8925 - binary_crossentropy: 0.2527 - categorical_accuracy: 0.8925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25274521112442017,\n",
       " 0.8924999833106995,\n",
       " 0.8924999833106995,\n",
       " 0.25274503231048584,\n",
       " 0.8924999833106995]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = compile_model()\n",
    "model.fit(X_train, y_train, epochs = 100, verbose = 0)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_115\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Data (InputLayer)            [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "TargetHit (Dense)            (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 74\n",
      "Trainable params: 66\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to implement a robust validation method\n",
    "\n",
    "metric = tf.keras.metrics.Accuracy()\n",
    "yTrue = np.array([[0],[1],[0],[0],[1]])\n",
    "yPred = np.array([[0],[0],[0],[0],[1]]) \n",
    "metric.update_state(yTrue,yPred)\n",
    "metric.result().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2076 - accuracy: 0.9187 - binary_accuracy: 0.9187 - binary_crossentropy: 0.2076 - categorical_accuracy: 0.9187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2076467126607895,\n",
       " 0.918749988079071,\n",
       " 0.918749988079071,\n",
       " 0.20764651894569397,\n",
       " 0.918749988079071]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = compile_model()\n",
    "model.fit(X, y_binary, epochs = 50, verbose = 0)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_117\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Data (InputLayer)            [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "TargetHit (Dense)            (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 74\n",
      "Trainable params: 66\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good work done, try to get 98% !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of things learnt\n",
    "\n",
    "1. BatchNormalization greatly improves model performance\n",
    "2. Epochs don't seem to cause overfitting of data as suggested by Huthwaite, can you verify this?\n",
    "3. What does batchsize do exactly? How do you set it, what values should you choose?\n",
    "4. F1_score punishes models for misclassifying, whereas accuracy just describes how accurate the model is. The latter is more useful for cases where you REALLY don't want to misclassify\n",
    "5. loss defines how a model trains. There are different types of this that need to be explored\n",
    "6. type of optiisers ought to also be explored, to see if they make any difference with modelling?\n",
    "7. Evaluate shows you by default as the first value, the loss of the function. Any other values are metrics that are added on\n",
    "8. The autokeras model tends to overcomplicate models, may not be appropriate for this project\n",
    "9. K-Fold validation has not yet been used. What is grid search in this context?\n",
    "10. model complexity $\\propto$ # of neurons\n",
    "\n",
    "\n",
    "Links that might be useful:\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
    "\n",
    "https://autokeras.com/tutorial/structured_data_classification/\n",
    "\n",
    "https://www.machinecurve.com/index.php/2020/02/18/how-to-use-k-fold-cross-validation-with-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2\n",
    "\n",
    "Using the same model as before, will test if setting the uncorrelated variables (temperature and device weight) to 0 will improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['Air temperature (deg C)', 'Device weight (kg)']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Arm length (m)  Ball weight (kg)  Ball radius (mm)  \\\n",
      "1768       -0.116440         -0.632348         -1.387401   \n",
      "591         1.721609         -2.549631          1.354147   \n",
      "1310        0.324763         -0.172669         -0.831143   \n",
      "1424        1.318512          1.162827         -0.008651   \n",
      "384         0.383205          0.047390         -1.155000   \n",
      "...              ...               ...               ...   \n",
      "950        -0.745873          0.613965          2.134466   \n",
      "1993        0.563933         -0.989612         -0.549741   \n",
      "1064        1.253749         -0.955341          0.552465   \n",
      "742        -0.203538          2.121050          1.000592   \n",
      "595        -0.146467         -1.649562         -0.575591   \n",
      "\n",
      "      Air temperature (deg C)  Spring constant (N per m)  Device weight (kg)  \n",
      "1768                 0.245940                  -0.290462            0.213686  \n",
      "591                  1.489631                   0.560145            1.337117  \n",
      "1310                 1.075067                  -0.738173            0.705921  \n",
      "1424                -1.412315                   1.883061           -0.694567  \n",
      "384                  1.282349                   1.120834            1.075084  \n",
      "...                       ...                        ...                 ...  \n",
      "950                 -0.375906                   1.016590           -0.969456  \n",
      "1993                -1.619596                   0.617830            0.531227  \n",
      "1064                 1.075067                  -1.560475            0.025717  \n",
      "742                  0.245940                   0.574940           -1.694253  \n",
      "595                  0.245940                  -1.584873            1.675781  \n",
      "\n",
      "[400 rows x 6 columns] [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y_binary, test_size = 0.8, random_state = 23\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Arm length (m)  Ball weight (kg)  Ball radius (mm)  \\\n",
      "1768       -0.116440         -0.632348         -1.387401   \n",
      "591         1.721609         -2.549631          1.354147   \n",
      "1310        0.324763         -0.172669         -0.831143   \n",
      "1424        1.318512          1.162827         -0.008651   \n",
      "384         0.383205          0.047390         -1.155000   \n",
      "...              ...               ...               ...   \n",
      "950        -0.745873          0.613965          2.134466   \n",
      "1993        0.563933         -0.989612         -0.549741   \n",
      "1064        1.253749         -0.955341          0.552465   \n",
      "742        -0.203538          2.121050          1.000592   \n",
      "595        -0.146467         -1.649562         -0.575591   \n",
      "\n",
      "      Air temperature (deg C)  Spring constant (N per m)  Device weight (kg)  \n",
      "1768                      0.0                  -0.290462                 0.0  \n",
      "591                       0.0                   0.560145                 0.0  \n",
      "1310                      0.0                  -0.738173                 0.0  \n",
      "1424                      0.0                   1.883061                 0.0  \n",
      "384                       0.0                   1.120834                 0.0  \n",
      "...                       ...                        ...                 ...  \n",
      "950                       0.0                   1.016590                 0.0  \n",
      "1993                      0.0                   0.617830                 0.0  \n",
      "1064                      0.0                  -1.560475                 0.0  \n",
      "742                       0.0                   0.574940                 0.0  \n",
      "595                       0.0                  -1.584873                 0.0  \n",
      "\n",
      "[400 rows x 6 columns] [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 990us/step - loss: 0.2239 - accuracy: 0.9131 - binary_accuracy: 0.9131 - binary_crossentropy: 0.2239 - categorical_accuracy: 0.9131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22388547658920288,\n",
       " 0.9131249785423279,\n",
       " 0.9131249785423279,\n",
       " 0.22388526797294617,\n",
       " 0.9131249785423279]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = compile_model()\n",
    "model.fit(X_train, y_train, epochs = 100, verbose = 0)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_119\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Data (InputLayer)            [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "TargetHit (Dense)            (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 74\n",
      "Trainable params: 66\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like setting the useless variables to zero actually makes the model worse... this is a very curious observation. Could it do with the fact that you have a relu, and then you have a batch normalization stage which then converts the zeros to something that isn't 0?\n",
    "\n",
    "\n",
    "Need to find a way to automate this... \n",
    "\n",
    "- I want to test this on different models\n",
    "    - each of the models will need to have their hyperparamters tuned\n",
    "- For each model, I want to be able to test it on 3 x 2 datasets. 3 refers to types of scaling: standard scaler, maxabsscaler, minmaxscaler, and 2 refers to a) with temp and device included, b) with tmep and device excluded\n",
    "- need to experiment with dropout too \n",
    "\n",
    "\n",
    "I need to make sure that the method of validation is more robust (use cross validation maybe, and then try on different seeds?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.8, random_state = 23)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "def uncompiled_model():\n",
    "    inputs =  Input(shape = (6,), name = 'Data')\n",
    "    x = Dense(4, activation = 'relu', name = 'dense_1')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(4, activation = 'relu', name = 'dense_2')(x)\n",
    "\n",
    "    outputs = Dense(1, activation = None, name = 'TargetHit')(x)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def compile_model():\n",
    "    model = uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"accuracy\",\n",
    "                 \"binary_accuracy\",\n",
    "                 \"binary_crossentropy\",\n",
    "                 \"categorical_accuracy\"\n",
    "                ],\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.8769 - binary_accuracy: 0.8769 - binary_crossentropy: 0.3471 - categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11992811411619186,\n",
       " 0.8768749833106995,\n",
       " 0.8768749833106995,\n",
       " 0.3471261262893677,\n",
       " 1.0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = compile_model()\n",
    "model.fit(X_train, y_train, epochs = 50, verbose = 0)\n",
    "yhat = model.predict(X_test)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1516405 ],\n",
       "       [1.9468489 ],\n",
       "       [0.12171301],\n",
       "       ...,\n",
       "       [0.67125535],\n",
       "       [1.8183311 ],\n",
       "       [0.30547097]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
