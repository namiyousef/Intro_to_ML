{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1\n",
    "\n",
    "This includes the modelling for the first dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arm length (m)</th>\n",
       "      <th>Ball weight (kg)</th>\n",
       "      <th>Ball radius (mm)</th>\n",
       "      <th>Air temperature (deg C)</th>\n",
       "      <th>Spring constant (N per m)</th>\n",
       "      <th>Device weight (kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.080169</td>\n",
       "      <td>0.295992</td>\n",
       "      <td>-1.672519</td>\n",
       "      <td>-0.168624</td>\n",
       "      <td>1.894558</td>\n",
       "      <td>0.153154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.530990</td>\n",
       "      <td>2.110671</td>\n",
       "      <td>2.590811</td>\n",
       "      <td>1.489631</td>\n",
       "      <td>0.522109</td>\n",
       "      <td>0.717173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.870428</td>\n",
       "      <td>1.411470</td>\n",
       "      <td>0.095824</td>\n",
       "      <td>-1.619596</td>\n",
       "      <td>1.728095</td>\n",
       "      <td>0.336045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.847603</td>\n",
       "      <td>1.505591</td>\n",
       "      <td>-0.684953</td>\n",
       "      <td>0.245940</td>\n",
       "      <td>-1.370214</td>\n",
       "      <td>0.139830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.379235</td>\n",
       "      <td>0.814349</td>\n",
       "      <td>-0.073455</td>\n",
       "      <td>-1.619596</td>\n",
       "      <td>-1.303393</td>\n",
       "      <td>-0.271138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Arm length (m)  Ball weight (kg)  Ball radius (mm)  \\\n",
       "0       -0.080169          0.295992         -1.672519   \n",
       "1       -0.530990          2.110671          2.590811   \n",
       "2        1.870428          1.411470          0.095824   \n",
       "3       -0.847603          1.505591         -0.684953   \n",
       "4       -1.379235          0.814349         -0.073455   \n",
       "\n",
       "   Air temperature (deg C)  Spring constant (N per m)  Device weight (kg)  \n",
       "0                -0.168624                   1.894558            0.153154  \n",
       "1                 1.489631                   0.522109            0.717173  \n",
       "2                -1.619596                   1.728095            0.336045  \n",
       "3                 0.245940                  -1.370214            0.139830  \n",
       "4                -1.619596                  -1.303393           -0.271138  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('../Data/dataset1_scaled.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arm length (m)\n",
       "0.291903    0.0\n",
       "0.247545    1.0\n",
       "0.483827    1.0\n",
       "0.216393    0.0\n",
       "0.164084    0.0\n",
       "Name: Target hit, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('../Data/dataset1.csv', index_col = 0)\n",
    "y = y[y.columns[-1]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras stuff\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y_binary = to_categorical(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_binary, test_size = 0.8, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    Dense(input_shape = (6,), units = 10, activation = 'relu')\n",
    ") # add first dense layer\n",
    "model.add(\n",
    "    Dense(units = 10, activation = 'sigmoid')\n",
    ")\n",
    "model.add(\n",
    "    Dense(units = 2, activation = 'sigmoid')\n",
    ")\n",
    "\n",
    "#model.add(\n",
    "#    BatchNormalization()\n",
    "#)\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'sgd',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7684 - accuracy: 0.5075\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7606 - accuracy: 0.5075\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7538 - accuracy: 0.5075\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7482 - accuracy: 0.5075\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7434 - accuracy: 0.5075\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7392 - accuracy: 0.5075\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7354 - accuracy: 0.5075\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7324 - accuracy: 0.5075\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.5075\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7270 - accuracy: 0.5075\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7248 - accuracy: 0.5075\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.5075\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7211 - accuracy: 0.5075\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7196 - accuracy: 0.5075\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7182 - accuracy: 0.5075\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7169 - accuracy: 0.5075\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7157 - accuracy: 0.5075\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7146 - accuracy: 0.5075\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7136 - accuracy: 0.5075\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7126 - accuracy: 0.5075\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7117 - accuracy: 0.5075\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7109 - accuracy: 0.5075\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.5075\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7094 - accuracy: 0.5075\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.5075\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.5075\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7075 - accuracy: 0.5075\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7070 - accuracy: 0.5075\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.5075\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7060 - accuracy: 0.5075\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.5075\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7051 - accuracy: 0.5075\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.5075\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7041 - accuracy: 0.5075\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7037 - accuracy: 0.5075\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7033 - accuracy: 0.5075\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.5075\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.5075\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.5075\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.5075\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7013 - accuracy: 0.5075\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7009 - accuracy: 0.5050\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.5050\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7002 - accuracy: 0.5025\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.5025\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6995 - accuracy: 0.5025\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6992 - accuracy: 0.5050\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.5025\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 978us/step - loss: 0.6985 - accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.5025\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.5025\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6970 - accuracy: 0.5050\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.5025\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.5025\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5025\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.5025\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.5075\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5025\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6998 - accuracy: 0.43 - 0s 2ms/step - loss: 0.6948 - accuracy: 0.5025\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.4975\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4975\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5050\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5100\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5075\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5050\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5025\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5050\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5100\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5100\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5075\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5100\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5100\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5100\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5075\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5100\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5100\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5100\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5125\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5125\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5125\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5125\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5150\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5175\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5150\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5125\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5175\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5175\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5250\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5450\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5475\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5350\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5425\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5525\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa1a7b25050>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6835912466049194 / Test accuracy: 0.5462499856948853\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                70        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 202\n",
      "Trainable params: 202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade numpy==1.18\n",
    "#!pip install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc4\n",
    "#!pip install autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import autokeras as ak\\n\\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.8, random_state = 23)\\n\\nclf = ak.StructuredDataClassifier(\\n    overwrite=True,\\n    max_trials=10)\\n\\nclf.fit(X_train, y_train,\\n    epochs=10)\\n\\n# Predict with the best model.\\n\\npredicted_y = clf.predict(X_test)\\n# Evaluate the best model with testing data.\\nclf.evaluate(X_test, y_test)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import autokeras as ak\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.8, random_state = 23)\n",
    "\n",
    "clf = ak.StructuredDataClassifier(\n",
    "    overwrite=True,\n",
    "    max_trials=10)\n",
    "\n",
    "clf.fit(X_train, y_train,\n",
    "    epochs=10)\n",
    "\n",
    "# Predict with the best model.\n",
    "\n",
    "predicted_y = clf.predict(X_test)\n",
    "# Evaluate the best model with testing data.\n",
    "clf.evaluate(X_test, y_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import tensorflow as tf\\n\\ntrain_set = tf.data.Dataset.from_tensor_slices((X_train.astype(np.unicode), y_train))\\ntest_set = tf.data.Dataset.from_tensor_slices((X_test.to_numpy().astype(np.unicode), y_test))\\n\\nclf = ak.StructuredDataClassifier(\\n    overwrite=True,\\n    max_trials=3)\\n# Feed the tensorflow Dataset to the classifier.\\nclf.fit(train_set, epochs=10)\\n# Predict with the best model.\\npredicted_y = clf.predict(test_set)\\n# Evaluate the best model with testing data.\\nprint(clf.evaluate(test_set))'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import tensorflow as tf\n",
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices((X_train.astype(np.unicode), y_train))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test.to_numpy().astype(np.unicode), y_test))\n",
    "\n",
    "clf = ak.StructuredDataClassifier(\n",
    "    overwrite=True,\n",
    "    max_trials=3)\n",
    "# Feed the tensorflow Dataset to the classifier.\n",
    "clf.fit(train_set, epochs=10)\n",
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(test_set)\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(test_set))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = clf.export_model()\\nmodel.summary()'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model = clf.export_model()\n",
    "model.summary()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target: to beat a model with accuracy = [0.36, 0.8925] (based on autokeras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step - loss: 0.6382 - accuracy: 0.6981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6382137537002563, 0.6981250047683716]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(input_shape = (6,), units = 32),\n",
    "        Dense(units = 32, activation = 'relu'),\n",
    "        Dense(units = 2, activation = 'tanh')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'sgd',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "y_binary = to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_binary, test_size = 0.8, random_state = 23)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 100, verbose = 0)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score\n",
    "\n",
    "# model is terrible..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.5081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6975393891334534, 0.5081250071525574]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(input_shape = (6,), units = 32),\n",
    "        Dense(units = 32, activation = 'relu'),\n",
    "        Dense(units = 32),\n",
    "        Dense(units = 32, activation = 'relu'),\n",
    "        Dense(units = 2, activation = 'tanh')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'sgd',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "y_binary = to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_binary, test_size = 0.8, random_state = 23)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 100, verbose = 0)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding code to make this process smoother..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LayerNormalization \n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "def uncompiled_model():\n",
    "    inputs =  Input(shape = (6,), name = 'Data')\n",
    "    x = Dense(4, activation = 'relu', name = 'dense_1')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(4, activation = 'relu', name = 'dense_2')(x)\n",
    "\n",
    "    outputs = Dense(2, activation = 'softmax', name = 'TargetHit')(x)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def compile_model():\n",
    "    model = uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"sgd\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\",\n",
    "                 \"binary_accuracy\",\n",
    "                 \"binary_crossentropy\",\n",
    "                 \"categorical_accuracy\"\n",
    "                ],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2527 - accuracy: 0.8925 - binary_accuracy: 0.8925 - binary_crossentropy: 0.2527 - categorical_accuracy: 0.8925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25274521112442017,\n",
       " 0.8924999833106995,\n",
       " 0.8924999833106995,\n",
       " 0.25274503231048584,\n",
       " 0.8924999833106995]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = compile_model()\n",
    "model.fit(X_train, y_train, epochs = 100, verbose = 0)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Data (InputLayer)            [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "TargetHit (Dense)            (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 74\n",
      "Trainable params: 66\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to implement a robust validation method\n",
    "\n",
    "metric = tf.keras.metrics.Accuracy()\n",
    "yTrue = np.array([[0],[1],[0],[0],[1]])\n",
    "yPred = np.array([[0],[0],[0],[0],[1]]) \n",
    "metric.update_state(yTrue,yPred)\n",
    "metric.result().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2055 - accuracy: 0.9156 - binary_accuracy: 0.9156 - binary_crossentropy: 0.2055 - categorical_accuracy: 0.9156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20552895963191986,\n",
       " 0.9156249761581421,\n",
       " 0.9156249761581421,\n",
       " 0.20552879571914673,\n",
       " 0.9156249761581421]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = compile_model()\n",
    "model.fit(X, y_binary, epochs = 50, verbose = 0)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Data (InputLayer)            [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "TargetHit (Dense)            (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 74\n",
      "Trainable params: 66\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good work done, try to get 98% !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of things learnt\n",
    "\n",
    "1. BatchNormalization greatly improves model performance\n",
    "2. Epochs don't seem to cause overfitting of data as suggested by Huthwaite, can you verify this?\n",
    "3. What does batchsize do exactly? How do you set it, what values should you choose?\n",
    "4. F1_score punishes models for misclassifying, whereas accuracy just describes how accurate the model is. The latter is more useful for cases where you REALLY don't want to misclassify\n",
    "5. loss defines how a model trains. There are different types of this that need to be explored\n",
    "6. type of optiisers ought to also be explored, to see if they make any difference with modelling?\n",
    "7. Evaluate shows you by default as the first value, the loss of the function. Any other values are metrics that are added on\n",
    "8. The autokeras model tends to overcomplicate models, may not be appropriate for this project\n",
    "9. K-Fold validation has not yet been used. What is grid search in this context?\n",
    "10. model complexity $\\propto$ # of neurons\n",
    "\n",
    "\n",
    "Links that might be useful:\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
    "\n",
    "https://autokeras.com/tutorial/structured_data_classification/\n",
    "\n",
    "https://www.machinecurve.com/index.php/2020/02/18/how-to-use-k-fold-cross-validation-with-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2\n",
    "\n",
    "Using the same model as before, will test if setting the uncorrelated variables (temperature and device weight) to 0 will improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['Air temperature (deg C)', 'Device weight (kg)']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Arm length (m)  Ball weight (kg)  Ball radius (mm)  \\\n",
      "1768       -0.116440         -0.632348         -1.387401   \n",
      "591         1.721609         -2.549631          1.354147   \n",
      "1310        0.324763         -0.172669         -0.831143   \n",
      "1424        1.318512          1.162827         -0.008651   \n",
      "384         0.383205          0.047390         -1.155000   \n",
      "...              ...               ...               ...   \n",
      "950        -0.745873          0.613965          2.134466   \n",
      "1993        0.563933         -0.989612         -0.549741   \n",
      "1064        1.253749         -0.955341          0.552465   \n",
      "742        -0.203538          2.121050          1.000592   \n",
      "595        -0.146467         -1.649562         -0.575591   \n",
      "\n",
      "      Air temperature (deg C)  Spring constant (N per m)  Device weight (kg)  \n",
      "1768                 0.245940                  -0.290462            0.213686  \n",
      "591                  1.489631                   0.560145            1.337117  \n",
      "1310                 1.075067                  -0.738173            0.705921  \n",
      "1424                -1.412315                   1.883061           -0.694567  \n",
      "384                  1.282349                   1.120834            1.075084  \n",
      "...                       ...                        ...                 ...  \n",
      "950                 -0.375906                   1.016590           -0.969456  \n",
      "1993                -1.619596                   0.617830            0.531227  \n",
      "1064                 1.075067                  -1.560475            0.025717  \n",
      "742                  0.245940                   0.574940           -1.694253  \n",
      "595                  0.245940                  -1.584873            1.675781  \n",
      "\n",
      "[400 rows x 6 columns] [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y_binary, test_size = 0.8, random_state = 23\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Arm length (m)  Ball weight (kg)  Ball radius (mm)  \\\n",
      "1768       -0.116440         -0.632348         -1.387401   \n",
      "591         1.721609         -2.549631          1.354147   \n",
      "1310        0.324763         -0.172669         -0.831143   \n",
      "1424        1.318512          1.162827         -0.008651   \n",
      "384         0.383205          0.047390         -1.155000   \n",
      "...              ...               ...               ...   \n",
      "950        -0.745873          0.613965          2.134466   \n",
      "1993        0.563933         -0.989612         -0.549741   \n",
      "1064        1.253749         -0.955341          0.552465   \n",
      "742        -0.203538          2.121050          1.000592   \n",
      "595        -0.146467         -1.649562         -0.575591   \n",
      "\n",
      "      Air temperature (deg C)  Spring constant (N per m)  Device weight (kg)  \n",
      "1768                      0.0                  -0.290462                 0.0  \n",
      "591                       0.0                   0.560145                 0.0  \n",
      "1310                      0.0                  -0.738173                 0.0  \n",
      "1424                      0.0                   1.883061                 0.0  \n",
      "384                       0.0                   1.120834                 0.0  \n",
      "...                       ...                        ...                 ...  \n",
      "950                       0.0                   1.016590                 0.0  \n",
      "1993                      0.0                   0.617830                 0.0  \n",
      "1064                      0.0                  -1.560475                 0.0  \n",
      "742                       0.0                   0.574940                 0.0  \n",
      "595                       0.0                  -1.584873                 0.0  \n",
      "\n",
      "[400 rows x 6 columns] [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2711 - accuracy: 0.9100 - binary_accuracy: 0.9100 - binary_crossentropy: 0.2711 - categorical_accuracy: 0.9100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27105334401130676,\n",
       " 0.9100000262260437,\n",
       " 0.9100000262260437,\n",
       " 0.2710531949996948,\n",
       " 0.9100000262260437]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = compile_model()\n",
    "model.fit(X_train, y_train, epochs = 100, verbose = 0)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Data (InputLayer)            [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "TargetHit (Dense)            (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 74\n",
      "Trainable params: 66\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like setting the useless variables to zero actually makes the model worse... this is a very curious observation. Could it do with the fact that you have a relu, and then you have a batch normalization stage which then converts the zeros to something that isn't 0?\n",
    "\n",
    "\n",
    "Need to find a way to automate this... \n",
    "\n",
    "- I want to test this on different models\n",
    "    - each of the models will need to have their hyperparamters tuned\n",
    "- For each model, I want to be able to test it on 3 x 2 datasets. 3 refers to types of scaling: standard scaler, maxabsscaler, minmaxscaler, and 2 refers to a) with temp and device included, b) with tmep and device excluded\n",
    "- need to experiment with dropout too \n",
    "\n",
    "\n",
    "I need to make sure that the method of validation is more robust (use cross validation maybe, and then try on different seeds?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.8, random_state = 23)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "def uncompiled_model():\n",
    "    inputs =  Input(shape = (6,), name = 'Data')\n",
    "    x = Dense(4, activation = 'relu', name = 'dense_1')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(4, activation = 'relu', name = 'dense_2')(x)\n",
    "\n",
    "    outputs = Dense(1, activation = None, name = 'TargetHit')(x)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def compile_model():\n",
    "    model = uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"accuracy\",\n",
    "                 \"binary_accuracy\",\n",
    "                 \"binary_crossentropy\",\n",
    "                 \"categorical_accuracy\"\n",
    "                ],\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.8913 - binary_accuracy: 0.8913 - binary_crossentropy: 0.2971 - categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10130862891674042,\n",
       " 0.8912500143051147,\n",
       " 0.8912500143051147,\n",
       " 0.2971213161945343,\n",
       " 1.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = compile_model()\n",
    "model.fit(X_train, y_train, epochs = 50, verbose = 0)\n",
    "yhat = model.predict(X_test)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1516405 ],\n",
       "       [1.9468489 ],\n",
       "       [0.12171301],\n",
       "       ...,\n",
       "       [0.67125535],\n",
       "       [1.8183311 ],\n",
       "       [0.30547097]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 3 - expeirmenting with and without a linear activation function at the end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_binary, test_size = 0.8, random_state = 23)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncompiled_model():\n",
    "    inputs =  Input(shape = (6,), name = 'Data')\n",
    "    x = Dense(4, activation = 'relu', name = 'dense_1')(inputs)\n",
    "    x = Dense(4, activation = 'relu', name = 'dense_2')(x)\n",
    "    x = BatchNormalizatio()(x)\n",
    "\n",
    "    outputs = Dense(2, activation = 'softmax', name = 'TargetHit')(x)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def compile_model():\n",
    "    model = uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"mean_squared_error\", # setting to MSE /w 'linear' activation \n",
    "        # batch normalization seems to somehow decrease how well the model \n",
    "        # performs... you need to look into this further\n",
    "        # is better than not\n",
    "        metrics=[\"accuracy\",\n",
    "                 \"binary_accuracy\",\n",
    "                 \"binary_crossentropy\",\n",
    "                 \"categorical_accuracy\"\n",
    "                ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BatchNormalizatio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-13a215174c0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-fd65290b446a>\u001b[0m in \u001b[0;36mcompile_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muncompiled_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     model.compile(\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-fd65290b446a>\u001b[0m in \u001b[0;36muncompiled_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dense_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dense_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalizatio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'TargetHit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BatchNormalizatio' is not defined"
     ]
    }
   ],
   "source": [
    "model = compile_model()\n",
    "print(model.metrics)\n",
    "scores = [[] for metric in range(4)]\n",
    "start = time.time()\n",
    "for j in range(10):\n",
    "    model.fit(X_train, y_train, epochs = 50, verbose = 0)\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    for i in range(4):\n",
    "        scores[i].append(score[i])\n",
    "\n",
    "for i in range(4):\n",
    "    print(sum(scores[i])/len(scores[i]))\n",
    "print(time.time()- start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.metrics.Mean object at 0x7fa18db9fe50>, <tensorflow.python.keras.metrics.MeanMetricWrapper object at 0x7fa18d6aee10>, <tensorflow.python.keras.metrics.MeanMetricWrapper object at 0x7fa18d6b5e10>, <tensorflow.python.keras.metrics.MeanMetricWrapper object at 0x7fa18d6abad0>, <tensorflow.python.keras.metrics.MeanMetricWrapper object at 0x7fa18da59310>]\n"
     ]
    }
   ],
   "source": [
    "# linear units are useful for optimization algorithms because they don't\n",
    "# saturate!\n",
    "print(model.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_121\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Data (InputLayer)            [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "TargetHit (Dense)            (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 58\n",
      "Trainable params: 58\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
