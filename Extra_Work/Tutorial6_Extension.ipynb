{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6_Extension\n",
    "\n",
    "In this tutorial I will explore neural networks using Keras from TensorFlow, and expand upon the content of tutorial 6. Broadly speaking, I will look at the following:\n",
    "\n",
    "- different types of activation functions\n",
    "- different options for setting up layers\n",
    "- understanding what the modules dense and sequential actually do\n",
    "- create functions that will help with the coursework task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system libraries\n",
    "\n",
    "# mathematical\n",
    "import numpy as np\n",
    "\n",
    "# modelling\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# data \n",
    "from PythonFiles.datasets_huthwaite import gen_circular_distribution as circ_dist\n",
    "\n",
    "# plotting\n",
    "from PythonFiles.plotting import plot_classes\n",
    "import matplotlib.pyplot as plt\n",
    "# set styles\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing functionality\n",
    "\n",
    "Keras is an end-to-end model, i.e. a model that can be deployed within itself, and therefore does not need external functions / libraries to do preprocessing or analysis. This makes deployment very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.08908156 -0.23675686  1.32583843]\n",
      "tf.Tensor(\n",
      "[[-1.0890815 ]\n",
      " [-0.23675685]\n",
      " [ 1.3258383 ]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "X = np.array([20, 30, 50])\n",
    "y = np.array([27000, 45000, 78000])\n",
    "y_scaled = (y-y.mean())/y.std()\n",
    "print(y_scaled)\n",
    "\n",
    "normalizer = Normalization(axis=-1)\n",
    "normalizer.adapt(y)\n",
    "normalized_data = normalizer(y)\n",
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalizer function seems to add like a **standard scaler** for the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import model_to_dot\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x13b551a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2942141184.0000 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13bde2b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[20.]\n",
      " [30.]\n",
      " [50.]]\n"
     ]
    }
   ],
   "source": [
    "tensorboard = TensorBoard(\n",
    "  log_dir='.\\logs',\n",
    "  histogram_freq=1,\n",
    "  write_images=True\n",
    ")\n",
    "\n",
    "keras_callbacks = [\n",
    "  tensorboard\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Normalization(axis = -1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X,y,epochs = 1, batch_size = 32, callbacks = keras_callbacks)\n",
    "yhat = model.predict(X)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=./logs\n",
    "\n",
    "# have not learnt how to use the above, but seems extremely useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this normalization does not seem to do anything when added to a neural network. That said, the neural network used here actually has no \"dense\" layers, so in fact the output might change!\n",
    "\n",
    "For now I will show this quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.random import set_seed\n",
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2945834752.0000 - accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2945611776.0000 - accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2945392384.0000 - accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2945170176.0000 - accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2944936960.0000 - accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2944698368.0000 - accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2944472832.0000 - accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2944245760.0000 - accuracy: 0.0000e+0 - 0s 7ms/step - loss: 2944245760.0000 - accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2944014592.0000 - accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2943784192.0000 - accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2943550720.0000 - accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2943326464.0000 - accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2943099904.0000 - accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2942867456.0000 - accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2942629888.0000 - accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2942384128.0000 - accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2942133504.0000 - accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2941882624.0000 - accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2941624320.0000 - accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2941356800.0000 - accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2941078528.0000 - accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2940788992.0000 - accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2940488448.0000 - accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2940175616.0000 - accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2939855104.0000 - accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2939521280.0000 - accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2939176192.0000 - accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2938820352.0000 - accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2938449664.0000 - accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2938063104.0000 - accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2937660672.0000 - accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2937241600.0000 - accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2936804352.0000 - accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2936348928.0000 - accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2935874816.0000 - accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2935379968.0000 - accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2934864128.0000 - accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2934327040.0000 - accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2933766912.0000 - accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2933183232.0000 - accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2932575488.0000 - accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2931941376.0000 - accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2931281152.0000 - accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2930594048.0000 - accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2929877248.0000 - accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2929131520.0000 - accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2928355328.0000 - accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2927547136.0000 - accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2926705920.0000 - accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2925830400.0000 - accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2924919808.0000 - accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2923972352.0000 - accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2922986496.0000 - accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2921962240.0000 - accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2920896512.0000 - accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2919789568.0000 - accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2918639616.0000 - accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2917444352.0000 - accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2916200192.0000 - accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2914907136.0000 - accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2913564672.0000 - accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2912170752.0000 - accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2910724096.0000 - accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2909222912.0000 - accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2907666688.0000 - accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2906052864.0000 - accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2904380160.0000 - accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2902647040.0000 - accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2900851712.0000 - accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2898993152.0000 - accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2897069056.0000 - accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2895077376.0000 - accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2893017344.0000 - accuracy: 0.0000e+00\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 2890886400.0000 - accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2888683264.0000 - accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2886405376.0000 - accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2884052224.0000 - accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2881621248.0000 - accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2879110400.0000 - accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2876518144.0000 - accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2873841920.0000 - accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2871080704.0000 - accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2868231936.0000 - accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2865293312.0000 - accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2862263552.0000 - accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2859139072.0000 - accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2855918080.0000 - accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2852597760.0000 - accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2849177088.0000 - accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2845652736.0000 - accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2842022656.0000 - accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2838283776.0000 - accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2834435328.0000 - accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2830473472.0000 - accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2826396928.0000 - accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2822202880.0000 - accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2817889024.0000 - accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2813453056.0000 - accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2808892672.0000 - accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2804205568.0000 - accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2799389184.0000 - accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2794441472.0000 - accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2789359872.0000 - accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2784142080.0000 - accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2778785536.0000 - accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2773288192.0000 - accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2767647232.0000 - accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2761860864.0000 - accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2755926016.0000 - accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2749841152.0000 - accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2743602432.0000 - accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2737209600.0000 - accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2730658816.0000 - accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2723948032.0000 - accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2717075200.0000 - accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2710037760.0000 - accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2702833664.0000 - accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2695459840.0000 - accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2687915264.0000 - accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2680196608.0000 - accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2672301568.0000 - accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2664228864.0000 - accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2655975680.0000 - accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2647539968.0000 - accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2638919936.0000 - accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2630112512.0000 - accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2621116672.0000 - accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2611929344.0000 - accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2602549248.0000 - accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2592973824.0000 - accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 988us/step - loss: 2583201792.0000 - accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 913us/step - loss: 2573230848.0000 - accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 823us/step - loss: 2563059456.0000 - accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2552685056.0000 - accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 970us/step - loss: 2542106880.0000 - accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2531322112.0000 - accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2520329984.0000 - accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2509128960.0000 - accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2497716480.0000 - accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2486092032.0000 - accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2474253568.0000 - accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2462200320.0000 - accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2449930496.0000 - accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2437442816.0000 - accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2424736768.0000 - accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2411811072.0000 - accuracy: 0.0000e+00\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step - loss: 2398663936.0000 - accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2385295616.0000 - accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2371705088.0000 - accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2357890560.0000 - accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2343852800.0000 - accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2329590528.0000 - accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2315103488.0000 - accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2300390656.0000 - accuracy: 0.0000e+0 - 0s 1ms/step - loss: 2300390656.0000 - accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2285453568.0000 - accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2270290688.0000 - accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2254902272.0000 - accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2239288320.0000 - accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2223449344.0000 - accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2207385856.0000 - accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2191097856.0000 - accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2174586624.0000 - accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2157851904.0000 - accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2140895616.0000 - accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2123718016.0000 - accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2106320384.0000 - accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2088704640.0000 - accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2070871552.0000 - accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2052822912.0000 - accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2034560640.0000 - accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2016086400.0000 - accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1997402496.0000 - accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1978510720.0000 - accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1959413888.0000 - accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1940114432.0000 - accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1920615296.0000 - accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1900918784.0000 - accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1881028608.0000 - accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1860947840.0000 - accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1840679552.0000 - accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1820227968.0000 - accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1799596672.0000 - accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1778789760.0000 - accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1757810688.0000 - accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1736664576.0000 - accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1715356032.0000 - accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1693889536.0000 - accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1672269952.0000 - accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1650502784.0000 - accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1628593024.0000 - accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1606546560.0000 - accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1584368640.0000 - accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1562065536.0000 - accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1539643776.0000 - accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1517108864.0000 - accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1494467584.0000 - accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1471727104.0000 - accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1448893824.0000 - accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1425975168.0000 - accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1402978176.0000 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13baebe60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "THIS IS MY YHAT:  [[ 9782.815]\n",
      " [14526.075]\n",
      " [24012.594]]\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# layer without normalization\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=10, activation='relu', input_dim=1))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X,y,epochs = 200, batch_size = 32)\n",
    "yhat = model.predict(X)\n",
    "print(\"THIS IS MY YHAT: \",yhat)\n",
    "plot_model(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2946569472.0000 - accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2946407168.0000 - accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2946243328.0000 - accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2946079488.0000 - accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2945925888.0000 - accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2945782528.0000 - accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2945640192.0000 - accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2945498112.0000 - accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2945356544.0000 - accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2945214464.0000 - accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2945078016.0000 - accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2944943360.0000 - accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2944810240.0000 - accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2944674048.0000 - accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2944533760.0000 - accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2944391424.0000 - accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2944248576.0000 - accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2944105472.0000 - accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 970us/step - loss: 2943962368.0000 - accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2943814400.0000 - accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2943660800.0000 - accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2943503104.0000 - accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2943339264.0000 - accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2943169792.0000 - accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2942996224.0000 - accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2942817024.0000 - accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2942630912.0000 - accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2942437120.0000 - accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2942234880.0000 - accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2942027008.0000 - accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2941812480.0000 - accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2941588736.0000 - accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2941356032.0000 - accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2941113600.0000 - accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2940860672.0000 - accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2940597504.0000 - accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2940322048.0000 - accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2940035072.0000 - accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2939734784.0000 - accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2939421440.0000 - accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2939094784.0000 - accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2938754304.0000 - accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2938398976.0000 - accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2938028288.0000 - accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2937643008.0000 - accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2937240576.0000 - accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2936822016.0000 - accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2936385792.0000 - accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2935931904.0000 - accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2935459584.0000 - accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2934968320.0000 - accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2934456320.0000 - accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2933924096.0000 - accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2933370880.0000 - accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2932796160.0000 - accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2932198144.0000 - accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2931577088.0000 - accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2930931712.0000 - accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2930262016.0000 - accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2929566720.0000 - accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2928844800.0000 - accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2928095232.0000 - accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2927318272.0000 - accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2926512128.0000 - accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2925676288.0000 - accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2924809472.0000 - accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2923911424.0000 - accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2922981120.0000 - accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2922017024.0000 - accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2921019136.0000 - accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2919985408.0000 - accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2918915840.0000 - accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2917808896.0000 - accuracy: 0.0000e+00\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 2916664064.0000 - accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2915479552.0000 - accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2914254848.0000 - accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2912988416.0000 - accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2911680512.0000 - accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2910328064.0000 - accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2908931328.0000 - accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2907489024.0000 - accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2906000128.0000 - accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2904451840.0000 - accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2902851328.0000 - accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2901196544.0000 - accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2899487744.0000 - accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2897723392.0000 - accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2895901952.0000 - accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2894023680.0000 - accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2892086528.0000 - accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2890089728.0000 - accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2888031488.0000 - accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2885910528.0000 - accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2883726080.0000 - accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2881476352.0000 - accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2879160320.0000 - accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2876777216.0000 - accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2874323712.0000 - accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2871799808.0000 - accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2869204224.0000 - accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2866535424.0000 - accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2863791872.0000 - accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2860971776.0000 - accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2858073856.0000 - accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2855097344.0000 - accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2852039936.0000 - accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2848899840.0000 - accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2845676800.0000 - accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2842368512.0000 - accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2838973184.0000 - accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2835490048.0000 - accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2831917056.0000 - accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2828253184.0000 - accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2824496384.0000 - accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2820645120.0000 - accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2816698112.0000 - accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2812653568.0000 - accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2808509696.0000 - accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2804265728.0000 - accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2799919360.0000 - accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2795469312.0000 - accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2790914304.0000 - accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2786252032.0000 - accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2781480448.0000 - accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2776570112.0000 - accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2771536640.0000 - accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2766381568.0000 - accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2761104384.0000 - accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2755704576.0000 - accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2750181632.0000 - accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2744532992.0000 - accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2738758912.0000 - accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2732857344.0000 - accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2726826240.0000 - accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2720665344.0000 - accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2714372096.0000 - accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2707945216.0000 - accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2701383424.0000 - accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2694685440.0000 - accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2687849472.0000 - accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2680873472.0000 - accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2673756928.0000 - accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2666497280.0000 - accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2659094016.0000 - accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2651544832.0000 - accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2643849472.0000 - accuracy: 0.0000e+00\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 2636004864.0000 - accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2628011008.0000 - accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2619865856.0000 - accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2611567360.0000 - accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2603115776.0000 - accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2594508544.0000 - accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2585744128.0000 - accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2576822272.0000 - accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2567741696.0000 - accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2558500096.0000 - accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2549096960.0000 - accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2539531008.0000 - accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2529801984.0000 - accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2519907072.0000 - accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2509846528.0000 - accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2499618816.0000 - accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2489222912.0000 - accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2478658816.0000 - accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2467924224.0000 - accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2457019392.0000 - accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2445942784.0000 - accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2434693888.0000 - accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2423272192.0000 - accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2411677184.0000 - accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2399907840.0000 - accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2387964160.0000 - accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2375844864.0000 - accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2363550208.0000 - accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2351079168.0000 - accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2338432256.0000 - accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2325609472.0000 - accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2312609280.0000 - accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2299432192.0000 - accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2286078720.0000 - accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2272548352.0000 - accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2258834176.0000 - accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2244941568.0000 - accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2230845952.0000 - accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2216567808.0000 - accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2202101760.0000 - accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2187449856.0000 - accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2172612352.0000 - accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2157590272.0000 - accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2142385664.0000 - accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2126997888.0000 - accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2111428608.0000 - accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2095678464.0000 - accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2079748736.0000 - accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2063640192.0000 - accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2047354368.0000 - accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2030892416.0000 - accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2014255744.0000 - accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1997446016.0000 - accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1980464768.0000 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13b7153b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "THIS IS MY YHAT:  [[ 5695.6895]\n",
      " [ 8452.477 ]\n",
      " [13966.05  ]]\n"
     ]
    }
   ],
   "source": [
    "# layer with normalization as the first layer\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Normalization(axis = -1))\n",
    "model.add(Dense(units=10, activation='relu', input_dim=1))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X,y,epochs = 200, batch_size = 32)\n",
    "yhat = model.predict(X)\n",
    "print(\"THIS IS MY YHAT: \",yhat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.41426981 -5.61248608 -4.00891863] [-5.8242188  -4.9718941  -3.40929881]\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 23.1515 - accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.4371 - accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.9020 - accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.6322 - accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.5488 - accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.6341 - accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9535 - accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.4313 - accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0457 - accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8091 - accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6905 - accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7399 - accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9168 - accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1976 - accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5928 - accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0978 - accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2157 - accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2365 - accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5046 - accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2653 - accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2032 - accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1484 - accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1030 - accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0283 - accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0295 - accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.0000e+00\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0217 - accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0201 - accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0198 - accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0197 - accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0196 - accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.0000e+ - 0s 2ms/step - loss: 0.0195 - accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.0000e+00\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0190 - accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0188 - accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13b95ac20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "THIS IS MY YHAT:  [[-5.6874213]\n",
      " [-4.9905076]\n",
      " [-3.5966809]]\n"
     ]
    }
   ],
   "source": [
    "# layer with normalization before input\n",
    "X1 = np.array([20, 30, 50])\n",
    "X1 = (X1- X1.sum())/X1.std()\n",
    "y1 = np.array([27000, 45000, 78000])\n",
    "y1 = (y1- y1.sum())/y1.std()\n",
    "print(X1,y1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=10, activation='relu', input_dim=1))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X1,y1,epochs = 200, batch_size = 32)\n",
    "yhat = model.predict(X1)\n",
    "print(\"THIS IS MY YHAT: \",yhat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, adding the normalisation layer before has improved the outcome. I'm unclear what adding 'normalization' to the neural network does. This is quite interesting, because it does not actually do anything when there are no dense layers. My understanding is that the neural networks starts performing calculations only when the dense layer (or another type) is applied. Then the normalisation will just act as it's supposed to. It's very interesting though.\n",
    "\n",
    "For now I will leave this be; it seems to me like it is not used that frequently anyways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of layers\n",
    "\n",
    "Keras has many different layer types.\n",
    "\n",
    "These are:\n",
    "\n",
    "- Dense: these are just regular neural network layers. Nothing fancy.\n",
    "- Normalization: \n",
    "    - BatchNormalization: at the end of a layer, after all the weights have been applied and the activation functions have been specified, it normalizes the outputs \n",
    "    - LayerNoramlization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x13b041e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2945999872.0000 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13b783dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "THIS IS MY YHAT:  [[0.00290057]\n",
      " [0.00290057]\n",
      " [0.00290057]]\n"
     ]
    }
   ],
   "source": [
    "# batch normalization\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LayerNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LayerNormalization())\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "X = np.array([20.0, 30.0, 50.0])\n",
    "y = np.array([27000, 45000, 78000])\n",
    "\n",
    "\n",
    "model.fit(X,y,epochs = 1, batch_size = 1)\n",
    "yhat = model.predict(X)\n",
    "print(\"THIS IS MY YHAT: \",yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multidimensional problems\n",
    "\n",
    "\n",
    "NOTE: you need to experiment with setting the inputs of one of the features to 0 completely, and seeing how that impacts the model.\n",
    "\n",
    "Alternatively, you need to examine the concept of using a dropout layer: that might actually remove the redundancies!\n",
    "\n",
    "Need to also explore the concept of putting 'linear' activation in the last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of activation functions and their use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6 Specific content\n",
    "\n",
    "We have two circular distributions and we want to be able to classify them correctly.\n",
    "Doing this question will help me pratcise once again setting up a neural netowrk problem, but also it'll aid me with understanding the output of a neural network layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = circ_dist()\n",
    "plot_classes(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the values (they already have mean 0, but let's change SD)\n",
    "\n",
    "X = (X - X.mean(axis = 0))/X.std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_classes(X,y) # it has indeed done so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "\n",
    "\"\"\"model = Sequential(\n",
    "    [Dense(units = 10, input_shape = (2,), activation = 'relu'),\n",
    "    Dense(units = 200, activation = 'relu'),\n",
    "     Dense(units = 200, activation = 'relu'),\n",
    "     Dense(units = 2, activation = 'tanh')\n",
    "])\"\"\"\n",
    "\n",
    "model = Sequential(\n",
    "[\n",
    "    Dense(units = 6, input_shape = (2,), activation = 'relu'),\n",
    "    Dense(units = 6, activation = 'relu'),\n",
    "    Dense(units = 6, activation = 'relu'),\n",
    "    Dense(units = 2, activation = 'softmax')\n",
    "    \n",
    "]\n",
    ")\n",
    "# note, you must either use the model.add feature, or place the layers into a list\n",
    "# note, your y value that you use for training must be compatible with that of the final\n",
    "# layer\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'sgd',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "16/16 [==============================] - 0s 808us/step - loss: 0.6950 - accuracy: 0.5800\n",
      "Epoch 2/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.6180\n",
      "Epoch 3/250\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.6477 - accuracy: 0.6020\n",
      "Epoch 4/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6336 - accuracy: 0.6280\n",
      "Epoch 5/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6234 - accuracy: 0.7040\n",
      "Epoch 6/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6160 - accuracy: 0.7140\n",
      "Epoch 7/250\n",
      "16/16 [==============================] - 0s 928us/step - loss: 0.6104 - accuracy: 0.7140\n",
      "Epoch 8/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.7140\n",
      "Epoch 9/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.7140\n",
      "Epoch 10/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.7140\n",
      "Epoch 11/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7140\n",
      "Epoch 12/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5953 - accuracy: 0.7140\n",
      "Epoch 13/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.7140\n",
      "Epoch 14/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.7140\n",
      "Epoch 15/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5917 - accuracy: 0.7140\n",
      "Epoch 16/250\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.5910 - accuracy: 0.7140\n",
      "Epoch 17/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.7140\n",
      "Epoch 18/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7140\n",
      "Epoch 19/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.7140\n",
      "Epoch 20/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.7140\n",
      "Epoch 21/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5894 - accuracy: 0.7140\n",
      "Epoch 22/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.7140\n",
      "Epoch 23/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5889 - accuracy: 0.7140\n",
      "Epoch 24/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.7140\n",
      "Epoch 25/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7140\n",
      "Epoch 26/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7140\n",
      "Epoch 27/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.7140\n",
      "Epoch 28/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5881 - accuracy: 0.7140\n",
      "Epoch 29/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5878 - accuracy: 0.7140\n",
      "Epoch 30/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5876 - accuracy: 0.7140\n",
      "Epoch 31/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.7140\n",
      "Epoch 32/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5873 - accuracy: 0.7140\n",
      "Epoch 33/250\n",
      "16/16 [==============================] - 0s 789us/step - loss: 0.5871 - accuracy: 0.7140\n",
      "Epoch 34/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5869 - accuracy: 0.7140\n",
      "Epoch 35/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5869 - accuracy: 0.7140\n",
      "Epoch 36/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.7140\n",
      "Epoch 37/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.7140\n",
      "Epoch 38/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5862 - accuracy: 0.7140\n",
      "Epoch 39/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5861 - accuracy: 0.7140\n",
      "Epoch 40/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.7140\n",
      "Epoch 41/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7140\n",
      "Epoch 42/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7140\n",
      "Epoch 43/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.7140\n",
      "Epoch 44/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7140\n",
      "Epoch 45/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.7140\n",
      "Epoch 46/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7140\n",
      "Epoch 47/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5847 - accuracy: 0.7140\n",
      "Epoch 48/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5845 - accuracy: 0.7140\n",
      "Epoch 49/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.7140\n",
      "Epoch 50/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5841 - accuracy: 0.7140\n",
      "Epoch 51/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5839 - accuracy: 0.7140\n",
      "Epoch 52/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.7140\n",
      "Epoch 53/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5835 - accuracy: 0.7140\n",
      "Epoch 54/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.7140\n",
      "Epoch 55/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5831 - accuracy: 0.7140\n",
      "Epoch 56/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7140\n",
      "Epoch 57/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5827 - accuracy: 0.7140\n",
      "Epoch 58/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7140\n",
      "Epoch 59/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5823 - accuracy: 0.7140\n",
      "Epoch 60/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5823 - accuracy: 0.7140\n",
      "Epoch 61/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5819 - accuracy: 0.7140\n",
      "Epoch 62/250\n",
      "16/16 [==============================] - 0s 977us/step - loss: 0.5818 - accuracy: 0.7140\n",
      "Epoch 63/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5816 - accuracy: 0.7140\n",
      "Epoch 64/250\n",
      "16/16 [==============================] - 0s 952us/step - loss: 0.5814 - accuracy: 0.7140\n",
      "Epoch 65/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.7140\n",
      "Epoch 66/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.7140\n",
      "Epoch 67/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5808 - accuracy: 0.7140\n",
      "Epoch 68/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5806 - accuracy: 0.7140\n",
      "Epoch 69/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5803 - accuracy: 0.7140\n",
      "Epoch 70/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.7140\n",
      "Epoch 71/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.7140\n",
      "Epoch 72/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.7140\n",
      "Epoch 73/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7140\n",
      "Epoch 74/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.7140\n",
      "Epoch 75/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.7140\n",
      "Epoch 76/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5787 - accuracy: 0.7140\n",
      "Epoch 77/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.7140\n",
      "Epoch 78/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5782 - accuracy: 0.7140\n",
      "Epoch 79/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7140\n",
      "Epoch 80/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5777 - accuracy: 0.7140\n",
      "Epoch 81/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.7140\n",
      "Epoch 82/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 890us/step - loss: 0.5772 - accuracy: 0.7140\n",
      "Epoch 83/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5770 - accuracy: 0.7140\n",
      "Epoch 84/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.7140\n",
      "Epoch 85/250\n",
      "16/16 [==============================] - 0s 975us/step - loss: 0.5765 - accuracy: 0.7140\n",
      "Epoch 86/250\n",
      "16/16 [==============================] - 0s 955us/step - loss: 0.5763 - accuracy: 0.7140\n",
      "Epoch 87/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7140\n",
      "Epoch 88/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.7140\n",
      "Epoch 89/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.7140\n",
      "Epoch 90/250\n",
      "16/16 [==============================] - 0s 901us/step - loss: 0.5753 - accuracy: 0.7140\n",
      "Epoch 91/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.7140\n",
      "Epoch 92/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.7140\n",
      "Epoch 93/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.7140\n",
      "Epoch 94/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.7140\n",
      "Epoch 95/250\n",
      "16/16 [==============================] - 0s 894us/step - loss: 0.5739 - accuracy: 0.7140\n",
      "Epoch 96/250\n",
      "16/16 [==============================] - 0s 893us/step - loss: 0.5735 - accuracy: 0.7140\n",
      "Epoch 97/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.7140\n",
      "Epoch 98/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5730 - accuracy: 0.7140\n",
      "Epoch 99/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.7140\n",
      "Epoch 100/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7140\n",
      "Epoch 101/250\n",
      "16/16 [==============================] - 0s 931us/step - loss: 0.5723 - accuracy: 0.7140\n",
      "Epoch 102/250\n",
      "16/16 [==============================] - 0s 953us/step - loss: 0.5720 - accuracy: 0.7140\n",
      "Epoch 103/250\n",
      "16/16 [==============================] - 0s 986us/step - loss: 0.5717 - accuracy: 0.7140\n",
      "Epoch 104/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7140\n",
      "Epoch 105/250\n",
      "16/16 [==============================] - 0s 982us/step - loss: 0.5713 - accuracy: 0.7140\n",
      "Epoch 106/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7140\n",
      "Epoch 107/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.7140\n",
      "Epoch 108/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7140\n",
      "Epoch 109/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7140\n",
      "Epoch 110/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7140\n",
      "Epoch 111/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7140\n",
      "Epoch 112/250\n",
      "16/16 [==============================] - 0s 986us/step - loss: 0.5693 - accuracy: 0.7140\n",
      "Epoch 113/250\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.5691 - accuracy: 0.7140\n",
      "Epoch 114/250\n",
      "16/16 [==============================] - 0s 952us/step - loss: 0.5689 - accuracy: 0.7140\n",
      "Epoch 115/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7140\n",
      "Epoch 116/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.7140\n",
      "Epoch 117/250\n",
      "16/16 [==============================] - 0s 937us/step - loss: 0.5679 - accuracy: 0.7140\n",
      "Epoch 118/250\n",
      "16/16 [==============================] - 0s 993us/step - loss: 0.5676 - accuracy: 0.7140\n",
      "Epoch 119/250\n",
      "16/16 [==============================] - 0s 970us/step - loss: 0.5674 - accuracy: 0.7140\n",
      "Epoch 120/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7140\n",
      "Epoch 121/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7140\n",
      "Epoch 122/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7140\n",
      "Epoch 123/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.7140\n",
      "Epoch 124/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7140\n",
      "Epoch 125/250\n",
      "16/16 [==============================] - 0s 973us/step - loss: 0.5653 - accuracy: 0.7140\n",
      "Epoch 126/250\n",
      "16/16 [==============================] - 0s 976us/step - loss: 0.5650 - accuracy: 0.7140\n",
      "Epoch 127/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5647 - accuracy: 0.7140\n",
      "Epoch 128/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7140\n",
      "Epoch 129/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.7140\n",
      "Epoch 130/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.7140\n",
      "Epoch 131/250\n",
      "16/16 [==============================] - 0s 910us/step - loss: 0.5631 - accuracy: 0.7140\n",
      "Epoch 132/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5627 - accuracy: 0.7140\n",
      "Epoch 133/250\n",
      "16/16 [==============================] - 0s 979us/step - loss: 0.5623 - accuracy: 0.7140\n",
      "Epoch 134/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.7140\n",
      "Epoch 135/250\n",
      "16/16 [==============================] - 0s 957us/step - loss: 0.5616 - accuracy: 0.7140\n",
      "Epoch 136/250\n",
      "16/16 [==============================] - 0s 923us/step - loss: 0.5610 - accuracy: 0.7140\n",
      "Epoch 137/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5605 - accuracy: 0.7140\n",
      "Epoch 138/250\n",
      "16/16 [==============================] - 0s 820us/step - loss: 0.5601 - accuracy: 0.7140\n",
      "Epoch 139/250\n",
      "16/16 [==============================] - 0s 953us/step - loss: 0.5596 - accuracy: 0.7140\n",
      "Epoch 140/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7140\n",
      "Epoch 141/250\n",
      "16/16 [==============================] - 0s 834us/step - loss: 0.5585 - accuracy: 0.7140\n",
      "Epoch 142/250\n",
      "16/16 [==============================] - 0s 944us/step - loss: 0.5581 - accuracy: 0.7140\n",
      "Epoch 143/250\n",
      "16/16 [==============================] - 0s 983us/step - loss: 0.5575 - accuracy: 0.7140\n",
      "Epoch 144/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.7140\n",
      "Epoch 145/250\n",
      "16/16 [==============================] - 0s 995us/step - loss: 0.5565 - accuracy: 0.7140\n",
      "Epoch 146/250\n",
      "16/16 [==============================] - 0s 963us/step - loss: 0.5557 - accuracy: 0.7140\n",
      "Epoch 147/250\n",
      "16/16 [==============================] - 0s 951us/step - loss: 0.5554 - accuracy: 0.7140\n",
      "Epoch 148/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.7140\n",
      "Epoch 149/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7140\n",
      "Epoch 150/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.7140\n",
      "Epoch 151/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7140\n",
      "Epoch 152/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5523 - accuracy: 0.7140\n",
      "Epoch 153/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.7140\n",
      "Epoch 154/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.7140\n",
      "Epoch 155/250\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5500 - accuracy: 0.68 - 0s 1ms/step - loss: 0.5506 - accuracy: 0.7140\n",
      "Epoch 156/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5500 - accuracy: 0.7140\n",
      "Epoch 157/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5492 - accuracy: 0.7140\n",
      "Epoch 158/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5486 - accuracy: 0.7140\n",
      "Epoch 159/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.7140\n",
      "Epoch 160/250\n",
      "16/16 [==============================] - 0s 940us/step - loss: 0.5475 - accuracy: 0.7140\n",
      "Epoch 161/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.7140\n",
      "Epoch 162/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 951us/step - loss: 0.5460 - accuracy: 0.7140\n",
      "Epoch 163/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7140\n",
      "Epoch 164/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.7140\n",
      "Epoch 165/250\n",
      "16/16 [==============================] - 0s 914us/step - loss: 0.5440 - accuracy: 0.7140\n",
      "Epoch 166/250\n",
      "16/16 [==============================] - 0s 961us/step - loss: 0.5433 - accuracy: 0.7140\n",
      "Epoch 167/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.7140\n",
      "Epoch 168/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5417 - accuracy: 0.7140\n",
      "Epoch 169/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5410 - accuracy: 0.7140\n",
      "Epoch 170/250\n",
      "16/16 [==============================] - 0s 964us/step - loss: 0.5403 - accuracy: 0.7140\n",
      "Epoch 171/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7140\n",
      "Epoch 172/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.7140\n",
      "Epoch 173/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.7140\n",
      "Epoch 174/250\n",
      "16/16 [==============================] - 0s 939us/step - loss: 0.5369 - accuracy: 0.7140\n",
      "Epoch 175/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.7140\n",
      "Epoch 176/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7140\n",
      "Epoch 177/250\n",
      "16/16 [==============================] - 0s 885us/step - loss: 0.5344 - accuracy: 0.7140\n",
      "Epoch 178/250\n",
      "16/16 [==============================] - 0s 835us/step - loss: 0.5336 - accuracy: 0.7140\n",
      "Epoch 179/250\n",
      "16/16 [==============================] - 0s 908us/step - loss: 0.5327 - accuracy: 0.7140\n",
      "Epoch 180/250\n",
      "16/16 [==============================] - 0s 904us/step - loss: 0.5318 - accuracy: 0.7140\n",
      "Epoch 181/250\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5307 - accuracy: 0.7140\n",
      "Epoch 182/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7140\n",
      "Epoch 183/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7140\n",
      "Epoch 184/250\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7140\n",
      "Epoch 185/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7140\n",
      "Epoch 186/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5260 - accuracy: 0.7140\n",
      "Epoch 187/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5250 - accuracy: 0.7140\n",
      "Epoch 188/250\n",
      "16/16 [==============================] - 0s 935us/step - loss: 0.5243 - accuracy: 0.7140\n",
      "Epoch 189/250\n",
      "16/16 [==============================] - 0s 993us/step - loss: 0.5231 - accuracy: 0.7140\n",
      "Epoch 190/250\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.5221 - accuracy: 0.7140\n",
      "Epoch 191/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.7140\n",
      "Epoch 192/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.7140\n",
      "Epoch 193/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.7140\n",
      "Epoch 194/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.7140\n",
      "Epoch 195/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7140\n",
      "Epoch 196/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7140\n",
      "Epoch 197/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7140\n",
      "Epoch 198/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7140\n",
      "Epoch 199/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7140\n",
      "Epoch 200/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7140\n",
      "Epoch 201/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7140\n",
      "Epoch 202/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7140\n",
      "Epoch 203/250\n",
      "16/16 [==============================] - 0s 936us/step - loss: 0.5085 - accuracy: 0.7140\n",
      "Epoch 204/250\n",
      "16/16 [==============================] - 0s 917us/step - loss: 0.5075 - accuracy: 0.7140\n",
      "Epoch 205/250\n",
      "16/16 [==============================] - 0s 908us/step - loss: 0.5062 - accuracy: 0.7140\n",
      "Epoch 206/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7140\n",
      "Epoch 207/250\n",
      "16/16 [==============================] - 0s 937us/step - loss: 0.5042 - accuracy: 0.7140\n",
      "Epoch 208/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7140\n",
      "Epoch 209/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.7140\n",
      "Epoch 210/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7140\n",
      "Epoch 211/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.7140\n",
      "Epoch 212/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.7140\n",
      "Epoch 213/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7140\n",
      "Epoch 214/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7140\n",
      "Epoch 215/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7140\n",
      "Epoch 216/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7140\n",
      "Epoch 217/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7140\n",
      "Epoch 218/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7140\n",
      "Epoch 219/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7140\n",
      "Epoch 220/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7140\n",
      "Epoch 221/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7140\n",
      "Epoch 222/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7140\n",
      "Epoch 223/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.7160\n",
      "Epoch 224/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7160\n",
      "Epoch 225/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7160\n",
      "Epoch 226/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7160\n",
      "Epoch 227/250\n",
      "16/16 [==============================] - 0s 853us/step - loss: 0.4826 - accuracy: 0.7160\n",
      "Epoch 228/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7160\n",
      "Epoch 229/250\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7160\n",
      "Epoch 230/250\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4793 - accuracy: 0.7160 0s - loss: 0.4873 - accuracy: 0.\n",
      "Epoch 231/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7180\n",
      "Epoch 232/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7200\n",
      "Epoch 233/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.7180\n",
      "Epoch 234/250\n",
      "16/16 [==============================] - 0s 995us/step - loss: 0.4749 - accuracy: 0.7180\n",
      "Epoch 235/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7180\n",
      "Epoch 236/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7160\n",
      "Epoch 237/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7100\n",
      "Epoch 238/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7100\n",
      "Epoch 239/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7160\n",
      "Epoch 240/250\n",
      "16/16 [==============================] - 0s 980us/step - loss: 0.4689 - accuracy: 0.7200\n",
      "Epoch 241/250\n",
      "16/16 [==============================] - 0s 901us/step - loss: 0.4678 - accuracy: 0.7180\n",
      "Epoch 242/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 957us/step - loss: 0.4670 - accuracy: 0.7200\n",
      "Epoch 243/250\n",
      "16/16 [==============================] - 0s 964us/step - loss: 0.4658 - accuracy: 0.7180\n",
      "Epoch 244/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7120\n",
      "Epoch 245/250\n",
      "16/16 [==============================] - 0s 904us/step - loss: 0.4639 - accuracy: 0.7100\n",
      "Epoch 246/250\n",
      "16/16 [==============================] - 0s 871us/step - loss: 0.4627 - accuracy: 0.6960\n",
      "Epoch 247/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.6780\n",
      "Epoch 248/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.6780\n",
      "Epoch 249/250\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.6700\n",
      "Epoch 250/250\n",
      "16/16 [==============================] - 0s 947us/step - loss: 0.4577 - accuracy: 0.6540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13c1f4050>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y_train, epochs = 250, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "yhat = model.predict(X)\n",
    "y_plot = yhat[:,1]\n",
    "\n",
    "y_plot[yhat[:,1] > yhat[:,0]] = 1\n",
    "y_plot[y_plot != 1] = 0\n",
    "\n",
    "plot_classes(X,y_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Imperial",
   "language": "python",
   "name": "ml_imperial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
